<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Configuration · MPI.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="MPI.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">MPI.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">MPI.jl</a></li><li class="is-active"><a class="tocitem" href>Configuration</a><ul class="internal"><li><a class="tocitem" href="#Using-a-system-provided-MPI-backend"><span>Using a system-provided MPI backend</span></a></li><li><a class="tocitem" href="#Using-an-alternative-JLL-provided-MPI-library"><span>Using an alternative JLL-provided MPI library</span></a></li><li><a class="tocitem" href="#Configuration-of-the-MPI.jl-testsuite"><span>Configuration of the MPI.jl testsuite</span></a></li><li><a class="tocitem" href="#Migration-from-MPI.jl-version-0.19-or-earlier"><span>Migration from MPI.jl version 0.19 or earlier</span></a></li></ul></li><li><a class="tocitem" href="../usage/">Usage</a></li><li><a class="tocitem" href="../knownissues/">Known issues</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/01-hello/">Hello world</a></li><li><a class="tocitem" href="../examples/02-broadcast/">Broadcast</a></li><li><a class="tocitem" href="../examples/03-reduce/">Reduce</a></li><li><a class="tocitem" href="../examples/04-sendrecv/">Send/receive</a></li><li><a class="tocitem" href="../examples/05-job_schedule/">Job Scheduling</a></li><li><a class="tocitem" href="../examples/06-scatterv/">Scatterv and Gatherv</a></li><li><a class="tocitem" href="../examples/07-rma_active/">Active RMA</a></li><li><a class="tocitem" href="../examples/08-rma_passive/">Passive RMA</a></li><li><a class="tocitem" href="../examples/09-graph_communication/">Graph Communication</a></li></ul></li><li><span class="tocitem">Reference</span><ul><li><a class="tocitem" href="../reference/mpipreferences/">MPIPreferences.jl</a></li><li><a class="tocitem" href="../reference/library/">Library information</a></li><li><a class="tocitem" href="../reference/environment/">Environment</a></li><li><a class="tocitem" href="../reference/comm/">Communicators</a></li><li><a class="tocitem" href="../reference/buffers/">Buffers</a></li><li><a class="tocitem" href="../reference/pointtopoint/">Point-to-point communication</a></li><li><a class="tocitem" href="../reference/collective/">Collective communication</a></li><li><a class="tocitem" href="../reference/onesided/">One-sided communication</a></li><li><a class="tocitem" href="../reference/topology/">Topology</a></li><li><a class="tocitem" href="../reference/io/">I/O</a></li><li><a class="tocitem" href="../reference/advanced/">Advanced</a></li></ul></li><li><a class="tocitem" href="../refindex/">Index</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Configuration</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Configuration</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaParallel/MPI.jl/blob/master/docs/src/configuration.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Configuration"><a class="docs-heading-anchor" href="#Configuration">Configuration</a><a id="Configuration-1"></a><a class="docs-heading-anchor-permalink" href="#Configuration" title="Permalink"></a></h1><p>By default, MPI.jl will download and link against the following MPI implementations:</p><ul><li><a href="https://docs.microsoft.com/en-us/message-passing-interface/microsoft-mpi">Microsoft MPI</a> on Windows</li><li><a href="http://www.mpich.org/">MPICH</a> on all other platforms</li></ul><p>This is suitable for most single-node use cases, but for larger systems, such as HPC clusters or multi-GPU machines, you will probably want to configure against a system-provided MPI implementation in order to exploit features such as fast network interfaces and CUDA-aware or ROCm-aware MPI interfaces.</p><p>The MPIPreferences.jl package allows the user to choose which MPI implementation to use in MPI.jl. It uses <a href="https://github.com/JuliaPackaging/Preferences.jl">Preferences.jl</a> to configure the MPI backend for each project separately. This provides a single source of truth that can be used for JLL packages (Julia packages providing C libraries) that link against MPI. It can be installed by</p><pre><code class="language-sh hljs">julia -e &#39;using Pkg; Pkg.add(&quot;MPIPreferences&quot;)&#39;</code></pre><h2 id="Using-a-system-provided-MPI-backend"><a class="docs-heading-anchor" href="#Using-a-system-provided-MPI-backend">Using a system-provided MPI backend</a><a id="Using-a-system-provided-MPI-backend-1"></a><a class="docs-heading-anchor-permalink" href="#Using-a-system-provided-MPI-backend" title="Permalink"></a></h2><h3 id="Requirements"><a class="docs-heading-anchor" href="#Requirements">Requirements</a><a id="Requirements-1"></a><a class="docs-heading-anchor-permalink" href="#Requirements" title="Permalink"></a></h3><p>MPI.jl requires a shared library installation of a C MPI library, supporting the MPI 3.0 standard or later. The following MPI implementations should work out-of-the-box with MPI.jl:</p><ul><li><a href="http://www.open-mpi.org/">Open MPI</a></li><li><a href="http://www.mpich.org/">MPICH</a> (v3.1 or later)</li><li><a href="https://software.intel.com/en-us/mpi-library">Intel MPI</a></li><li><a href="https://docs.microsoft.com/en-us/message-passing-interface/microsoft-mpi">Microsoft MPI</a></li><li><a href="https://www.ibm.com/us-en/marketplace/spectrum-mpi">IBM Spectrum MPI</a></li><li><a href="http://mvapich.cse.ohio-state.edu/">MVAPICH</a></li><li><a href="https://docs.nersc.gov/development/compilers/wrappers/">Cray MPICH</a></li><li><a href="https://www.fujitsu.com/global/about/resources/publications/technicalreview/2020-03/article07.html#cap-03">Fujitsu MPI</a></li><li><a href="https://support.hpe.com/hpesc/public/docDisplay?docLocale=en_US&amp;docId=a00105727en_us">HPE MPT/HMPT</a></li></ul><h3 id="Configuration-2"><a class="docs-heading-anchor" href="#Configuration-2">Configuration</a><a class="docs-heading-anchor-permalink" href="#Configuration-2" title="Permalink"></a></h3><p>Run <code>MPIPreferences.use_system_binary()</code>. This will attempt to locate and to identify any available MPI implementation, and create a file called <code>LocalPreferences.toml</code> adjacent to the current <code>Project.toml</code>.</p><pre><code class="language-sh hljs">julia --project -e &#39;using MPIPreferences; MPIPreferences.use_system_binary()&#39;</code></pre><p>If the implementation is changed, you will need to call this function again. See the <a href="../reference/mpipreferences/#MPIPreferences.use_system_binary"><code>MPIPreferences.use_system_binary</code></a> documentation for specific options.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>You can copy <code>LocalPreferences.toml</code> to a different project folder, but you must list <code>MPIPreferences</code> in the <code>[extras]</code> or <code>[deps]</code> section of the <code>Project.toml</code> for the settings to take effect.</p></div></div><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Due to a bug in Julia (until <code>v1.6.5</code> and <code>v1.7.1</code>), getting preferences from transitive dependencies is broken (<a href="https://github.com/JuliaPackaging/Preferences.jl/issues/24">Preferences.jl#24</a>). To fix this update your version of Julia, or add <code>MPIPreferences</code> as a direct dependency to your project.</p></div></div><h3 id="Notes-to-HPC-cluster-adminstators"><a class="docs-heading-anchor" href="#Notes-to-HPC-cluster-adminstators">Notes to HPC cluster adminstators</a><a id="Notes-to-HPC-cluster-adminstators-1"></a><a class="docs-heading-anchor-permalink" href="#Notes-to-HPC-cluster-adminstators" title="Permalink"></a></h3><p>Preferences are merged across the Julia load path, such that it is feasible to provide a module file that appends a path to <code>JULIA_LOAD_PATH</code> variable that contains system-wide preferences. The steps are as follows:</p><ol><li><p>Run <a href="../reference/mpipreferences/#MPIPreferences.use_system_binary"><code>MPIPreferences.use_system_binary()</code></a>, which will generate a file <code>LocalPreferences.toml</code> containing something like the following:</p><pre><code class="language-toml hljs">[MPIPreferences]
abi = &quot;OpenMPI&quot;
binary = &quot;system&quot;
libmpi = &quot;/software/mpi/lib/libmpi.so&quot;
mpiexec = &quot;/software/mpi/bin/mpiexec&quot;</code></pre></li><li><p>Create a file called <code>Project.toml</code> or <code>JuliaProject.toml</code> in a central location, for example <code>/software/mpi/julia</code> or in the same directory as the MPI library module, and add the following contents:</p><pre><code class="language-toml hljs">[extras]
MPIPreferences = &quot;3da0fdf6-3ccc-4f1b-acd9-58baa6c99267&quot;

[preferences.MPIPreferences]
abi = &quot;OpenMPI&quot;
binary = &quot;system&quot;
libmpi = &quot;/software/mpi/lib/libmpi.so&quot;
mpiexec = &quot;/software/mpi/bin/mpiexec&quot;</code></pre><p>updating the contents of the <code>[preferences.MPIPreferences]</code> section match those of the <code>[MPIPreferences]</code> in <code>LocalPreferences.toml</code>.</p></li><li><p>Append the directory containing the file to the <a href="https://docs.julialang.org/en/v1/manual/environment-variables/#JULIA_LOAD_PATH"><code>JULIA_LOAD_PATH</code></a> environment variable, with a colon (<code>:</code>) separator.</p><p>If this variable is <em>not</em> already set, it should be prefixed with a colon to ensure correct behavior of the Julia load path, e.g. <code>JULIA_LOAD_PATH=&quot;:/software/mpi/julia&quot;</code>. If using environment modules, this can be achieved with</p><pre><code class="nohighlight hljs">append-path  -d {} JULIA_LOAD_PATH :/software/mpi/julia</code></pre><p>in the corresponding module file (preferably the module file for the MPI installation or for Julia).</p><p>The user can still provide differing MPI configurations for each Julia project that will take precedent by modifying the local <code>Project.toml</code> or by providing a <code>LocalPreferences.toml</code> file.</p></li></ol><h2 id="Using-an-alternative-JLL-provided-MPI-library"><a class="docs-heading-anchor" href="#Using-an-alternative-JLL-provided-MPI-library">Using an alternative JLL-provided MPI library</a><a id="Using-an-alternative-JLL-provided-MPI-library-1"></a><a class="docs-heading-anchor-permalink" href="#Using-an-alternative-JLL-provided-MPI-library" title="Permalink"></a></h2><p>The following MPI implementations are provided as JLL packages and automatically obtained when installing MPI.jl:</p><ul><li><code>MicrosoftMPI_jll</code>: <a href="https://docs.microsoft.com/en-us/message-passing-interface/microsoft-mpi">Microsoft MPI</a> Default for Windows</li><li><code>MPICH_jll</code>: <a href="https://www.mpich.org/">MPICH</a>. Default for all other systems</li><li><code>OpenMPI_jll</code>: <a href="https://www.open-mpi.org/">Open MPI</a></li><li><code>MPItrampoline_jll</code>: <a href="https://github.com/eschnett/MPItrampoline">MPItrampoline</a>: an MPI forwarding layer.</li></ul><p>Call <a href="../reference/mpipreferences/#MPIPreferences.use_jll_binary"><code>MPIPreferences.use_jll_binary</code></a>, for example</p><pre><code class="language-sh hljs">julia --project -e &#39;using MPIPreferences; MPIPreferences.use_jll_binary(&quot;MPItrampoline_jll&quot;)&#39;</code></pre><h2 id="Configuration-of-the-MPI.jl-testsuite"><a class="docs-heading-anchor" href="#Configuration-of-the-MPI.jl-testsuite">Configuration of the MPI.jl testsuite</a><a id="Configuration-of-the-MPI.jl-testsuite-1"></a><a class="docs-heading-anchor-permalink" href="#Configuration-of-the-MPI.jl-testsuite" title="Permalink"></a></h2><h3 id="Testing-against-a-different-MPI-implementation"><a class="docs-heading-anchor" href="#Testing-against-a-different-MPI-implementation">Testing against a different MPI implementation</a><a id="Testing-against-a-different-MPI-implementation-1"></a><a class="docs-heading-anchor-permalink" href="#Testing-against-a-different-MPI-implementation" title="Permalink"></a></h3><p>The <code>LocalPreferences.toml</code> must be located within the <code>test</code> folder, you can either create it in place or copy it into place.</p><pre><code class="nohighlight hljs">~/MPI&gt; julia --project=test
julia&gt; using MPIPreferences
julia&gt; MPIPreferences.use_system_binary()
~/MPI&gt; rm test/Manifest.toml
~/MPI&gt; julia --project
(MPI) pkg&gt; test</code></pre><h3 id="Environment-variables"><a class="docs-heading-anchor" href="#Environment-variables">Environment variables</a><a id="Environment-variables-1"></a><a class="docs-heading-anchor-permalink" href="#Environment-variables" title="Permalink"></a></h3><p>The test suite can also be modified by the following variables:</p><ul><li><code>JULIA_MPI_TEST_NPROCS</code>: How many ranks to use within the tests</li><li><code>JULIA_MPI_TEST_ARRAYTYPE</code>: Set to <code>CuArray</code> or <code>ROCArray</code> to test the CUDA-aware interface with <a href="https://github.com/JuliaGPU/CUDA.jl"><code>CUDA.CuArray</code></a> or the ROCm-aware interface with  <a href="https://github.com/JuliaGPU/AMDGPU.jl"><code>AMDGPU.ROCArray</code></a> or buffers.</li><li><code>JULIA_MPI_TEST_BINARY</code>: Check that the specified MPI binary is used for the tests</li><li><code>JULIA_MPI_TEST_ABI</code>: Check that the specified MPI ABI is used for the tests</li></ul><h2 id="Migration-from-MPI.jl-version-0.19-or-earlier"><a class="docs-heading-anchor" href="#Migration-from-MPI.jl-version-0.19-or-earlier">Migration from MPI.jl version 0.19 or earlier</a><a id="Migration-from-MPI.jl-version-0.19-or-earlier-1"></a><a class="docs-heading-anchor-permalink" href="#Migration-from-MPI.jl-version-0.19-or-earlier" title="Permalink"></a></h2><p>Prior to MPI.jl version 0.20, environment variables were used to configure which MPI library to use. These have now been removed and no longer have any effect:</p><ul><li><code>JULIA_MPI_BINARY</code></li><li><code>JULIA_MPIEXEC</code></li><li><code>JULIA_MPIEXEC_ARGS</code></li><li><code>JULIA_MPI_INCLUDE_PATH</code></li><li><code>JULIA_MPI_CFLAGS</code></li><li><code>JULIA_MPICC</code></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« MPI.jl</a><a class="docs-footer-nextpage" href="../usage/">Usage »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Thursday 29 September 2022 17:33">Thursday 29 September 2022</span>. Using Julia version 1.8.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
